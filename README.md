
# 환경
* `t2.medium` 7대
    * ansible x 1
    * zookeeper x 3
    * kafka x 3
* `172.16.0.0 / 16`

# 카프카 구성 요소
## ZooKeeper
카프카의 메타데이터 관리 및 `브로커`의 헬스 체크를 담당
## Kafka 또는 Kafka cluster
여러 대의 `브로커`를 구성한 클러스터를 의미
## Broker
카프카 애플리케이션이 설치된 서버 또는 노드를 의미
## Producer
카프카로 `메시지`를 보내는 역할을 하는 클라이언트
## Consumer
카프카에서 `메시지`를 꺼내가는 역할을 하는 클라이언트
## Topic
`메시지` 피드들을 토픽으로 구분하고 `토픽`의 이름은 카프카 내에서 고유하다
### Repliction
각 메시지들을 여러 개로 복제해서 카프카 클러스터 내 브로커들에게 분산시킨다.

> 정확히는 토픽의 파티션이 리플리케이션된다.

**권장 리플리케이션 팩터 값**
* 테스트 또는 개발 환경: 1
* 운영 환경 (로그성 메시지로서 약간의 유실 허용): 2
* 운영 환경 (유실 허용 X): 3
> 4 또는 5 이상인 경우 디스크 공간을 더 많이 사용한다.

## Partition
병렬 처리 및 고성능을 얻기 위해 하나의 `토픽`을 여러 개로 나눈 것
* 파티션 번호는 0번 부터 시작한다.
* 초기 생성 후 언제든지 늘릴 수 있지만, 반대로 줄일 수 없기 때문에 LAG 등을 모니터링하면서 LAG을 통해 컨슈머에 지연이 없는지 확인하고 조금씩 늘려가는 방법을 추천한다. 
> LAG = (프로듀서가 보낸 메시지 수) - (컨슈머가 가져간 메시지 수)
- 파티션의 메시지가 저장되는 위치를 `오프셋(offset)`이라고 부른다.
- 각 파티션에서의 오프셋은 고유한 숫자로, 오프셋을 통해 메시지의 순서를 보장하고 컨슈머에서는 마지막까지 읽은 위치를 알 수 있다.

## Segment
`프로듀서`가 전송한 실제 `메시지`가 `브로커`의 로컬 디스크에 저장되는 파일
### 저장 과정
파티션이 1개인 test 토픽이 있다고 가정한다.
* 카프카 서버의 `/data/kafka-logs/{토픽 명}-{파티션 번호}`에서 로그 파일을 확인할 수 있다.
1. 프로듀서는 카프카의 test 토픽으로 메시지를 전송
1. test 토픽은 파티션0의 세그먼트 로그 파일에 저장
1. 로그 파일에 저장된 메시지는 컨슈머가 읽어갈 수 있다.
## Message 또는 Record
`프로듀서`가 `브로커`로 전송하거나 `컨슈머`가 읽어가는 데이터 조각

# 높은 처리량과 안전성을 지니게 된 카프카의 특성
## 분산 시스템
* 하나의 서버 또는 노드 등에 장애가 발생할 때 다른 서버 또는 노드가 대신 처리한다.
* 부하가 높은 경우에는 시스템 확장이 용이하다.
* 브로커는 온라인 상태에서 매우 간단하게 추가가 가능

## 페이지 캐시
* 직접 디스크에 읽고 쓰는 방식 대신 물리 메모리 중 애플리케이션이 사용하지 않는 일부 잔여 메모리를 활용
* 즉, 디스크 I/O에 대한 접근이 줄어들어 성능을 높일 수 있다.
## 배치 전송 처리
* 수많은 통신을 묶어서 처리 (배치 전송)
* 단건으로 통신할 때에 비해 네트워크 오버헤드를 줄일 수 있다.
## 압축 전송
지원 압축 타입
* 압축률이 높은 타입
    - gzip
    - zstd
- 빠른 응답 속도
    - lz4
    - snappy
## 고가용성 보장
고가용성을 보장하기 위해 `리플리케이션` 기능을 제공한다.

|리플리케이션 팩터 수|리더 수|팔로워 수|
|---|---|---|
|2|1|1|
|3|1|2|
|4|1|3|

팔로워의 수만큼 브로커의 디스크 공간도 소비되므로 이상적인 [리플리케이션 팩터 수](#repliction)를 유지해야한다.
